{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "\n",
    "import glob\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from operator import itemgetter \n",
    "from PIL import Image\n",
    "import os\n",
    "import json\n",
    "import cv2 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get annotations\n",
    "direc=os.path.join(\"/kaggle/input/face-mask-detection-dataset/Medical mask/Medical mask/Medical Mask/annotations/\")\n",
    "anno=[]\n",
    "for filn in os.listdir(direc):\n",
    "    with open(direc+filn) as f:\n",
    "        data=json.load(f)\n",
    "        anno.append({'filename':data['FileName'],'num_Anno':data['NumOfAnno'],'Annotations':data['Annotations']})\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sorting the list\n",
    "anno=sorted(anno, key=itemgetter('filename'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read train.csv\n",
    "train_csv=pd.read_csv(os.path.join(\"/kaggle/input/face-mask-detection-dataset/train.csv\"))\n",
    "train_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sorting the dataset\n",
    "train_csv.sort_values(by='name',inplace=True)\n",
    "train_csv.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#length of annotaion from train_csv\n",
    "print(train_csv.name.unique().shape)\n",
    "#length of annotaion from train_csv\n",
    "print(train_csv.classname.unique().shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image files\n",
    "images=os.listdir(os.path.join(\"/kaggle/input/face-mask-detection-dataset/Medical mask/Medical mask/Medical Mask/images\"))\n",
    "images.sort()\n",
    "print(images[:10])\n",
    "print(images[1698:1709])\n",
    "print(len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting images into train test\n",
    "train=images[1698:]\n",
    "test=images[:1698]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd '/kaggle/working'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting all test objects\n",
    "f= open(\"test.txt\",\"w+\")\n",
    "for ele in test:\n",
    "    f.write('/content/darknet/data/img/'+ele+'\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting height and width\n",
    "direc = os.path.abspath('/kaggle/input/face-mask-detection-dataset/Medical mask/Medical mask/Medical Mask/images/')\n",
    "dimen=[]\n",
    "for filn in os.listdir(direc):\n",
    "    img = Image.open(os.path.join(direc,filn))\n",
    "    width=img.size[0]\n",
    "    height=img.size[1]\n",
    "    dimen.append([filn,width,height])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging\n",
    "dimen_df=pd.DataFrame(dimen,columns=['name','width','height'])\n",
    "dimen_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('/kaggle/working/img')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting all train objects\n",
    "f= open(\"train.txt\",\"w+\")\n",
    "for ele in train:\n",
    "    f.write('/content/darknet/data/img/'+ele+'\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating obj.names file\n",
    "f= open(\"obj.names\",\"w+\")\n",
    "for ele in labels:\n",
    "    f.write(ele+'\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=train_csv.merge(dimen_df, on='name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting x1 x2 y1 y2 -> x_center, y_center, w, h\n",
    "def convert_df(df):\n",
    "    \n",
    "    x1 = np.array(df['x1'].values)\n",
    "    x2 = np.array(df['x2'].values)\n",
    "    y1 = np.array(df['y1'].values)\n",
    "    y2 = np.array(df['y2'].values)\n",
    "    w = np.array(df['width'].values)\n",
    "    h=np.array(df['height'].values)\n",
    "    dw = 1./w\n",
    "    dh = 1./h\n",
    "    x = (y1 + x1)/2.0\n",
    "    y = (y2 + x2)/2.0\n",
    "    w = y1-x1                                               \n",
    "    h = y2-x2                                                 \n",
    "    x = x*dw\n",
    "    w = w*dw\n",
    "    y = y*dh\n",
    "    h = h*dh\n",
    "    data = {'x':x, 'y':y, 'w':w, 'h':h}\n",
    "    df1 = pd.DataFrame(data=data)\n",
    "    return pd.concat([df, df1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final=convert_df(df)\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get labels\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "lb_make=LabelEncoder()\n",
    "df_final[\"labels\"] = lb_make.fit_transform(df_final[\"classname\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting list of labels with index as their categorical value\n",
    "labels=list(lb_make.inverse_transform([_ for _ in range(20)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting labels to dict\n",
    "label={i:labels[i] for i in range(len(labels))}\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shape df\n",
    "print(df_final.shape)\n",
    "#unique values \n",
    "print(len(df_final['name'].unique()))\n",
    "#show\n",
    "df_final['name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd '/kaggle/working'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get .txt file for every image\n",
    "for row in df_final.values:\n",
    "    filename = str(row[0][:4])+'.txt'\n",
    "\n",
    "    if os.path.exists(filename):\n",
    "        append_write = 'a' # append if already exists\n",
    "    else:\n",
    "        append_write = 'w' # make a new file if not\n",
    "\n",
    "    f = open(filename,append_write)\n",
    "    f.write('{0} {1} {2} {3} {4}\\n'.format(row[-1],row[-5],row[-4],row[-3],row[-2]))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name=[]\n",
    "for row in df_final.values:\n",
    "    name.append(row[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_unique=list(set(name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matchin_name=[]\n",
    "for item in name_unique:\n",
    "    matchin_name.append(item[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matchin_name_unique=list(set(matchin_name))\n",
    "len(matchin_name_unique)==len(matchin_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get duplicate\n",
    "import collections\n",
    "print([item for item, count in collections.Counter(matchin_name).items() if count > 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I created a obj.names file obj.data file train.txt file and .txt file for every image\n",
    "##### Now i will use these files to train on darknet using yolov3 in colab which is in different file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
